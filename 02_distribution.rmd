# Properties of Distributions

## Parameters of Univariate Distributions

- meristic characters (a range of discrete classes)
- metric characters (continuous scale)
- all-or-none or binary characters

- univariate distribution
- bivariate distribution
- multivariate distribution

- pdf: probability density function
- pmf: probability mass function

- **parameters**
- **estimates**
- Statisticians often denote parameters of a population with Greek symbols and to sample estimates with Roman symbols

- arithmetic mean, first moment about the origin, expected value, expectation
- population variance, second moment about the mean
- standard deviation (SD)
- coefficient of variation (the ratio of the standard deviation to the mean)
- third moment about the mean: asymmetry of a distribution, skewness
- coefficient of skewness (a ratio)

## The Normal Distribution

Normal distribution/Gaussian distribution (DeMoivre(1738), LaPlace(1778), and Gauss(1809)), the density function is given by

$$p(z) = (2\pi\sigma^2)^{-1/2}exp[-\frac{(z-\mu)^2}{2\sigma^2}]$$

- central limit theorem
- Gaussian fitness function (in the theory of stablizing selection)
- standard normal distribution

- third moment is 0
- fourth moment, kurtosis, leptokurtic vs platykurtic

### The truncated normal distribution

Under **truncation selection**, all individuals below a certain phenotype are culled from the population and hence have zero fitness. The critical phenotype, T, is called the **truncation point**. For a normally distributed pheontype, the density of the phenotype z after selection is

$$\frac{p(z)}{\int_T^\infty p(z)dz}$$
, the mean phenotype of the population above the threshold (i.e., after selection) can be writen as

$$\mu_s = \frac{\int_T^\infty zp(z)dz}{\int_T^\infty p(z)dz} = \mu+\frac{\sigma \times p_T}{\Phi_T}$$

, where

- $\Phi_T$ is the denominator $\int_T^\infty p(z)dz$, a measure of the intensity of selection;
- $p_T$ is the height of the standard normal curve at the truncation point T.

The change in the mean caused by selection ($\mu_s-\mu = \frac{\sigma \times p_T}{\Phi_T}$) is often denoted by S, the **directional selection differential**.

In a similar fashion, the variance of the selected population can be shown to be

$$\sigma^2_s = [1+\frac{p_Tz'}{\Phi_T}-(\frac{p_T}{\Phi_T})^2]\sigma^2$$
, where $z' = T - \mu$

```{r}
mu = 0; sigma=1
phi_T = 10^(seq(-3,0,by=0.05))
Tvalue = qnorm(phi_T, lower.tail=F)
p_T = dnorm(Tvalue)
mu_s = mu+sigma*p_T/phi_T
layout(matrix(1:2, 1, 2))
plot(x=log10(phi_T), y=(mu_s-mu)/sigma, type="l", xlab=expression(log[10]~Phi[T]), ylab=expression((mu[s]-mu)/sigma))
plot(x=log10(phi_T), y=(1+p_T*(Tvalue-mu)/phi_T-(p_T/phi_T)^2), type="l", xlab=expression(log[10]~Phi[T]), ylab=expression(sigma[s]^2/sigma^2))
```

## Confidence Intervals

- confidence limits or interval
- standard error (not standard deviation)